{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL workshop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCsL1rT5_Uno",
        "colab_type": "text"
      },
      "source": [
        "# Welcome to Introduction to Deep Learning with Tensorflow Workshop\n",
        "![alt text](data:image/png;base64,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)\n",
        "<br/>\n",
        "In this Workshop, we will be learning about TensorFlow and how to create a deep learning model.\n",
        "\n",
        "### What is TensorFlow?\n",
        "TensorFlow is a software library developed by google to help in machine learning. It allows developers to create dataflow graphs—structures that describe how data moves through a graph, or a series of processing nodes.\n",
        "\n",
        "Tensor is a multi-dimensional arrays of number which represents the data. Tensors flow through between operations and generate and output hence the name TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6cCuO9iMiAR",
        "colab_type": "text"
      },
      "source": [
        "## Libraries\n",
        "To start off, we will need to import tensorflow library. We also use the keras API\n",
        "\n",
        "In tensorflow, we have many available libraries and that we reduce the need of setting up the environment on our local machine to install tensorflow. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxEReUOg97uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_FHoCQO_Rfe",
        "colab_type": "text"
      },
      "source": [
        "In Traditional programming, we use the data given and the rules defined by us to get the desired output.\n",
        "\n",
        "In Machine learning, we will make use of data and the output of the data to create the rules. We use these rules later to predict the output using the data given. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qtzmBVtAIAg",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.bouvet.no/bouvet-deler/6-tips-for-getting-started-with-machine-learning/_/attachment/inline/8469beef-45b3-494b-a68a-2f19948844de:7222f3d165f068511023e7a1e4b817621ae17995/Screen%20Shot%202018-09-20%20at%2009.16.16.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95n2kHMOA5AL",
        "colab_type": "text"
      },
      "source": [
        "### 'Hello World' of Neural Network\n",
        "Below is a code to create a neural network which predicts y value for the given x value\n",
        "\n",
        "To get started, we first define a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYQ6E2Zz_G9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C4DZm4HFrZe",
        "colab_type": "text"
      },
      "source": [
        "In the above line Sequential defines the simplest model which constitutes of linear stack of layers. In our example, we have only one layer (Dense layer)\n",
        "\n",
        "In the dense layer, we have units=1 which means there is only one neuron and input_shape = [1] which means it intakes only one value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u13jzcTeFrD-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYCRRUK4GnFo",
        "colab_type": "text"
      },
      "source": [
        "Compile defines loss function and optimizer function which is used while training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb5KveOsGmWF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "688be501-d934-40f0-8e8a-7b9e0c654c7d"
      },
      "source": [
        "import numpy as np\n",
        "x = np.array([-2,-1,0,1,2,3,4], dtype = 'float')\n",
        "y = np.array([-3,-1,1,3,5,7,9], dtype = 'float')\n",
        "\n",
        "model.fit(x, y, epochs = 75) # the model is trained over 75 epochs using x and y "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.7052\n",
            "Epoch 2/75\n",
            "1/1 [==============================] - 0s 738us/step - loss: 7.8441\n",
            "Epoch 3/75\n",
            "1/1 [==============================] - 0s 768us/step - loss: 6.3505\n",
            "Epoch 4/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1514\n",
            "Epoch 5/75\n",
            "1/1 [==============================] - 0s 813us/step - loss: 4.1885\n",
            "Epoch 6/75\n",
            "1/1 [==============================] - 0s 669us/step - loss: 3.4148\n",
            "Epoch 7/75\n",
            "1/1 [==============================] - 0s 919us/step - loss: 2.7930\n",
            "Epoch 8/75\n",
            "1/1 [==============================] - 0s 672us/step - loss: 2.2929\n",
            "Epoch 9/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8904\n",
            "Epoch 10/75\n",
            "1/1 [==============================] - 0s 820us/step - loss: 1.5662\n",
            "Epoch 11/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.3047\n",
            "Epoch 12/75\n",
            "1/1 [==============================] - 0s 692us/step - loss: 1.0937\n",
            "Epoch 13/75\n",
            "1/1 [==============================] - 0s 782us/step - loss: 0.9231\n",
            "Epoch 14/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.7850\n",
            "Epoch 15/75\n",
            "1/1 [==============================] - 0s 892us/step - loss: 0.6729\n",
            "Epoch 16/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5817\n",
            "Epoch 17/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.5074\n",
            "Epoch 18/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.4465\n",
            "Epoch 19/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3965\n",
            "Epoch 20/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3553\n",
            "Epoch 21/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.3211\n",
            "Epoch 22/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2926\n",
            "Epoch 23/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2687\n",
            "Epoch 24/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2485\n",
            "Epoch 25/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2313\n",
            "Epoch 26/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.2166\n",
            "Epoch 27/75\n",
            "1/1 [==============================] - 0s 734us/step - loss: 0.2038\n",
            "Epoch 28/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1926\n",
            "Epoch 29/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1828\n",
            "Epoch 30/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1741\n",
            "Epoch 31/75\n",
            "1/1 [==============================] - 0s 764us/step - loss: 0.1662\n",
            "Epoch 32/75\n",
            "1/1 [==============================] - 0s 915us/step - loss: 0.1591\n",
            "Epoch 33/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1526\n",
            "Epoch 34/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1467\n",
            "Epoch 35/75\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1412\n",
            "Epoch 36/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1361\n",
            "Epoch 37/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1313\n",
            "Epoch 38/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1267\n",
            "Epoch 39/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1225\n",
            "Epoch 40/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1184\n",
            "Epoch 41/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1145\n",
            "Epoch 42/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1108\n",
            "Epoch 43/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1073\n",
            "Epoch 44/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.1039\n",
            "Epoch 45/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1006\n",
            "Epoch 46/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0975\n",
            "Epoch 47/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0944\n",
            "Epoch 48/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0915\n",
            "Epoch 49/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0887\n",
            "Epoch 50/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0860\n",
            "Epoch 51/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0833\n",
            "Epoch 52/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0808\n",
            "Epoch 53/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0783\n",
            "Epoch 54/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0759\n",
            "Epoch 55/75\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0736\n",
            "Epoch 56/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0714\n",
            "Epoch 57/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0692\n",
            "Epoch 58/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0671\n",
            "Epoch 59/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0650\n",
            "Epoch 60/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0631\n",
            "Epoch 61/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0612\n",
            "Epoch 62/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0593\n",
            "Epoch 63/75\n",
            "1/1 [==============================] - 0s 986us/step - loss: 0.0575\n",
            "Epoch 64/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0558\n",
            "Epoch 65/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0541\n",
            "Epoch 66/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0524\n",
            "Epoch 67/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0508\n",
            "Epoch 68/75\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0493\n",
            "Epoch 69/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0478\n",
            "Epoch 70/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0463\n",
            "Epoch 71/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0449\n",
            "Epoch 72/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0436\n",
            "Epoch 73/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0423\n",
            "Epoch 74/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0410\n",
            "Epoch 75/75\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0397\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc104babe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MuQ4L2GR0DZ",
        "colab_type": "text"
      },
      "source": [
        "x = [-2,-1,0,1,2,3,4] <br/>\n",
        "y = [-3,-1,1,3,5,7,9]\n",
        "\n",
        "As you can observe from the given data, y = 2x + 1. We have now used the data and trained a model using tensorflow. Lets see how accurate are the predictions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfqCrGxiRzfv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d8c433e-7ed7-4836-cb08-d00d7cf793c8"
      },
      "source": [
        "print(model.predict([5])) # y = 2 * 5 + 1 = 11\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[11.037718]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plROYAeSSqD8",
        "colab_type": "text"
      },
      "source": [
        "As you can see from the prediction, we got answer which is very close to the actual answer but its not the same. The reason for this is due to less data provided and the fact that neural networks deal in probability."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yvr6meQuU1uD",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 1 : Put a ring on it \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpm4AzLFWxax",
        "colab_type": "text"
      },
      "source": [
        "You want to buy a ring for yourself. You enter a store and they tell you the costing method of the ring. It costs 500 dollars to make the ring and it costs an extra 100 dollars for adding one diamond to the ring. So it would cost 600 dollars for a ring with 1 diamond and 1100 dollars for a ring with 6 diamonds. Create a model which takes an input for number of diamonds and outputs the cost\n",
        "\n",
        "Hint:<br/>\n",
        "1) use a small scale value(have your output in terms of thousands of dollars)<br/>\n",
        "2) Bigger the dataset, better the prediction<br/>\n",
        "3) In this case, number of epochs will improve your prediction but it leads to overfitting (we will discuss this later in the workshop) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbbZEqMFmt-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs= #YOUR CODE HERE\n",
        "ys= #YOUR CODE HERE\n",
        "model = #YOUR CODE HERE\n",
        "model.compile( #YOUR CODE HERE )\n",
        "model.fit( #YOUR CODE HERE )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo7JE9vcXs04",
        "colab_type": "text"
      },
      "source": [
        "After creating your model, check your answer with the code given below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2UMnX4TmyG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.predict([0]))\n",
        "print(model.predict([5]))\n",
        "print(model.predict([10]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTggVcGjYtAs",
        "colab_type": "text"
      },
      "source": [
        "## Computer Vision using Neural Networks\n",
        "In this part of the workshop, we will be working on the MNIST dataset which consists of images of digits 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gufk5FwOZa2i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "467a4414-b664-4fae-b311-6617b3a28af5"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhj4P-P9-BuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "21668d9b-51b8-4965-ab29-4b7f5a8251e6"
      },
      "source": [
        "print(len(training_images))\n",
        "print(len(test_images))\n",
        "#60000\n",
        "#10000"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSkLwmi6vOVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "bdeed42c-a129-4a36-f213-3a05ad56c501"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "image_index = 5 # You may select anything up to 60,000\n",
        "print(training_labels[image_index]) # The label is 8\n",
        "print(training_images[image_index].shape) # The image is 28 x 28 pixels\n",
        "plt.imshow(training_images[image_index], cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fdc651147b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plTi6Eg-6KVF",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-processing data\n",
        "Before we create our model, we need to normalize our image data and make sure all the images are of the same shape. If any of the images are in a different format, our model will give an error.\n",
        "\n",
        "We normalize our data by dividing all the pixel values by 255.0 . This is because the values for the pixels varies from 0-255. Normalizing the pixel value makes calculations easier for the model, therefore reducing the computation time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1ORQTSw530W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize the images\n",
        "training_images = training_images/ 255.0\n",
        "test_images = test_images/ 255.0\n",
        "\n",
        "#reshape the images\n",
        "training_images = training_images.reshape((training_images.shape[0], 28, 28, 1))\n",
        "test_images = test_images.reshape((test_images.shape[0], 28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUZVKKXEunoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "                            tf.keras.layers.Dense(10, activation = 'softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY1x54qXvORF",
        "colab_type": "text"
      },
      "source": [
        "While creating this model, we use a Flatten layer to take the matrice as an input and make it into an 1D list. This 1D list then goes through a neural network whose first layer has 128 nodes and second layer has 10 nodes.\n",
        "\n",
        "We have come across a new term called activation. It helps us define an activation function which is applied to the output of a neural network layer, which is then passed as the input to the next layer. There are several types of activation functions:\n",
        " - relu - if input x > 0 return x, else return 0\n",
        " - softmax - takes a set of values and picks the biggest value. eg - input [1,2,1,5,8,3,4,6,3] , output = [0,0,0,0,1,0,0,0,0]\n",
        " - sigmoid - returns 1/(1+exp(-x)) - used in binary classification\n",
        " - tanh - returns tan(x)\n",
        " - linear - returns m*x + c where m and c are weights changed while fitting the model\n",
        " - exponential - returns exp(x)\n",
        " - softplus - returns log(exp(x)+1)\n",
        " - softsign - returns x/(abs(x)+1)\n",
        "\n",
        " For this workshop, we will be using only relu, softmax and sigmoid.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4qB3codgk3v",
        "colab_type": "text"
      },
      "source": [
        "We will be using adam as the optimizer. There are different types of optimizers which can be beneficial in different scenarios. \n",
        "\n",
        "Adam is an adaptive learning rate optimization algorithm that’s been designed specifically for training deep neural networks. \n",
        "\n",
        "The learning rate of your optimizer changes over time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuf4Tk5jvNWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
        "model.compile(optimizer = adam,\n",
        "              loss= 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqNJ5gyEgcDK",
        "colab_type": "text"
      },
      "source": [
        "The amount that the weights are updated during training is referred to as the step size or the “learning rate.” If the value is too high, it will lead to over-fitting and if its too low, it will take more epochs to train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUYATqx9gg6i",
        "colab_type": "text"
      },
      "source": [
        "In the statement, we are fitting the model using only are training images and training labels. We are going to run it through 3 epochs and see the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUl8VQziy8i3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "07e36e60-aa50-4ff8-ef70-bf9c386205a5"
      },
      "source": [
        "history = model.fit(training_images, training_labels, epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2635 - accuracy: 0.9248\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1178 - accuracy: 0.9649\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0805 - accuracy: 0.9756\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0605 - accuracy: 0.9818\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0465 - accuracy: 0.9860\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0377 - accuracy: 0.9886\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0291 - accuracy: 0.9911\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0234 - accuracy: 0.9927\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0189 - accuracy: 0.9940\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0148 - accuracy: 0.9955\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0138 - accuracy: 0.9958\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0114 - accuracy: 0.9963\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0099 - accuracy: 0.9972\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0087 - accuracy: 0.9973\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0065 - accuracy: 0.9981\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0073 - accuracy: 0.9976\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9982\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0067 - accuracy: 0.9980\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0062 - accuracy: 0.9982\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9981\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0050 - accuracy: 0.9984\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0037 - accuracy: 0.9989\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0051 - accuracy: 0.9985\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0033 - accuracy: 0.9991\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0059 - accuracy: 0.9981\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa4KX-ytsenS",
        "colab_type": "text"
      },
      "source": [
        "Let's make prediction using our test set to check if the predictions are correct. We can see that when we get the prediction for an image from a model, it returns a list of float numbers. These numbers signify the probability of the image being that specific category. To find the category, we find the index of the biggest number in the list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRR0onlcm6eP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "c269b805-a639-49b8-fff2-aca840af07ec"
      },
      "source": [
        "import numpy as np\n",
        "image_no =384\n",
        "pred = model.predict(test_images)\n",
        "print(pred[image_no])\n",
        "print(np.argmax(pred[image_no]))\n",
        "print(test_labels[image_no])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.5563911e-18 9.2812926e-22 4.9453096e-20 2.3670656e-25 1.0808653e-24\n",
            " 4.5372839e-16 1.0000000e+00 6.8160918e-27 9.1691444e-21 7.7248510e-20]\n",
            "6\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2busvT4r4TUh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "76f2d820-cf69-4b41-b1d7-ec55ce66d203"
      },
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1298 - accuracy: 0.9756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12975753843784332, 0.975600004196167]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjCYMYCwwRmK",
        "colab_type": "text"
      },
      "source": [
        "### Model Evaluation\n",
        "\n",
        "![alt text](https://gblobscdn.gitbook.com/assets%2F-LvBP1svpACTB1R1x_U4%2F-LvNWUoWieQqaGmU_gl9%2F-LvNoby-llz4QzAK15nL%2Fimage.png?alt=media&token=41720ce9-bb66-4419-9bd8-640abf1fc415)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z88253UGWo9u",
        "colab_type": "text"
      },
      "source": [
        "**Optimum fitting**- Good fitting for a model. What we want our model to be."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nxWjwvSJhlN",
        "colab_type": "text"
      },
      "source": [
        "**Underfitting**- Case where the model has not learned enough from the training data. This results in low generalizations and unreliable predicition.\n",
        "\n",
        "Reasons for underfitting of data:\n",
        "1.   Model is not able to capture the underlying trend of the data.\n",
        "2.   The features are not sufficient to train the model.\n",
        "3. and more....\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnCAMaH0Fmo9",
        "colab_type": "text"
      },
      "source": [
        "**Overfitting**- Case where the overall loss is really small for the training data, but the generalization of the model is unreliable. Overfitting is like a human mugging up a concept instead of understanding it.\n",
        "\n",
        "Reasons for overfitting of data:\n",
        "\n",
        "\n",
        "1.   Noise in the data is used as a feature, this created misleading models leading to inaccurate prediction.\n",
        "2.   Some neurons have a very high weight which makes the whole model rely on only a few certain features and the other features are not used well.\n",
        "3.   The model is too complex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFkMrw6TV1Z0",
        "colab_type": "text"
      },
      "source": [
        "An example for overfitting is given below. In this example, we overfit the model by running too many epochs. \n",
        "\n",
        "This leads to the model memorizing the values for the given data and it doesnt perform well with new data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2k31HVa4lXI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "d82fc2d1-13e1-47d2-9410-0caac6736f8a"
      },
      "source": [
        "over_model = tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "                            tf.keras.layers.Dense(10, activation = 'softmax')])\n",
        " \n",
        "adam = keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
        "over_model.compile(optimizer = adam,\n",
        "              loss= 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        " \n",
        "train_acc = []\n",
        "train_loss = []\n",
        "test_acc = []\n",
        "test_loss = []\n",
        " \n",
        "for i in range(20):\n",
        "  history = over_model.fit(training_images, training_labels)\n",
        "  train_acc.append(history.history['accuracy'])\n",
        "  train_loss.append(history.history['loss'])\n",
        "  values = over_model.evaluate(test_images,test_labels)\n",
        "  test_acc.append(values[1])\n",
        "  test_loss.append(values[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 3s 2ms/step - loss: 2.8296 - accuracy: 0.8648\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.5291 - accuracy: 0.8826\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3822 - accuracy: 0.9102\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3672 - accuracy: 0.9092\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2916 - accuracy: 0.9277\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3204 - accuracy: 0.9231\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2543 - accuracy: 0.9354\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2952 - accuracy: 0.9361\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2318 - accuracy: 0.9426\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2370 - accuracy: 0.9391\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2180 - accuracy: 0.9462\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2365 - accuracy: 0.9447\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2050 - accuracy: 0.9482\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2620 - accuracy: 0.9435\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9531\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2573 - accuracy: 0.9480\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1833 - accuracy: 0.9548\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.9446\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1817 - accuracy: 0.9563\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2726 - accuracy: 0.9448\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1733 - accuracy: 0.9577\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2649 - accuracy: 0.9496\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1797 - accuracy: 0.9579\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2843 - accuracy: 0.9499\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1644 - accuracy: 0.9606\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.9494\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1715 - accuracy: 0.9591\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.9484\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1678 - accuracy: 0.9603\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3105 - accuracy: 0.9449\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1677 - accuracy: 0.9610\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3116 - accuracy: 0.9488\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1564 - accuracy: 0.9635\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3084 - accuracy: 0.9501\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1583 - accuracy: 0.9627\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.9504\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1563 - accuracy: 0.9625\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3772 - accuracy: 0.9513\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1578 - accuracy: 0.9636\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3555 - accuracy: 0.9464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtSCKmzK0Vfg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "f8c42cf4-687b-45df-aa1d-58d0cb9898f5"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "print(len(train_acc))\n",
        "plt.plot(range(20),train_acc,color = 'red')\n",
        "plt.plot(range(20),train_loss,color = 'blue')\n",
        "plt.plot(range(20),test_acc,color = 'green')\n",
        "plt.plot(range(20),test_loss,color = 'pink')\n",
        "plt.gca().legend(('train_acc','train_loss','test_acc','test_loss'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTSO1ZUYJCVG",
        "colab_type": "text"
      },
      "source": [
        "#### Preventing overfitting\n",
        "\n",
        "We are going to prevent overfitting using dropout layer.\n",
        "\n",
        "Dropout prevents overfitting. In overfitting, the model relys on only a few features. Dropout allows us to spread out the weights for all the neurons, making good use of all the features given to us. Dropout removes a few neurons from a specific layer during model fitting. The neurons are removed randomly. This allows the neurons to have a spread out weights."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wPu86DYaFoF",
        "colab_type": "text"
      },
      "source": [
        "The code for dropout is given below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYMV0h5Hale9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drop_model = tf.keras.Sequential([tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "                            tf.keras.layers.Dropout(0.25),\n",
        "                            tf.keras.layers.Dense(10, activation = 'softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75qwqjEGcaUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
        "drop_model.compile(optimizer = adam,\n",
        "              loss= 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWeKeMiGaXJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "4636aebf-60dd-4968-96af-732a9fd5763e"
      },
      "source": [
        "train_acc = []\n",
        "train_loss = []\n",
        "test_acc = []\n",
        "test_loss = []\n",
        "\n",
        "for i in range(20):\n",
        "  history = drop_model.fit(training_images, training_labels)\n",
        "  train_acc.append(history.history['accuracy'])\n",
        "  train_loss.append(history.history['loss'])\n",
        "  values = drop_model.evaluate(test_images,test_labels)\n",
        "  test_acc.append(values[1])\n",
        "  test_loss.append(values[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 3s 2ms/step - loss: 2.5433 - accuracy: 0.7340\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6023 - accuracy: 0.8554\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6614 - accuracy: 0.8239\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.9044\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5369 - accuracy: 0.8534\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3172 - accuracy: 0.9269\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4720 - accuracy: 0.8761\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2926 - accuracy: 0.9292\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4443 - accuracy: 0.8827\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2924 - accuracy: 0.9266\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4142 - accuracy: 0.8908\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2806 - accuracy: 0.9373\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3968 - accuracy: 0.8945\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2775 - accuracy: 0.9413\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3777 - accuracy: 0.9007\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2594 - accuracy: 0.9415\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3777 - accuracy: 0.9012\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2780 - accuracy: 0.9418\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3623 - accuracy: 0.9065\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.9393\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3639 - accuracy: 0.9080\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.9263\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3605 - accuracy: 0.9107\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2733 - accuracy: 0.9417\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3446 - accuracy: 0.9117\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2914 - accuracy: 0.9477\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3462 - accuracy: 0.9133\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.9375\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3369 - accuracy: 0.9164\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3082 - accuracy: 0.9446\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3427 - accuracy: 0.9136\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2817 - accuracy: 0.9469\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3338 - accuracy: 0.9156\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.9392\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3377 - accuracy: 0.9160\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.9447\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3345 - accuracy: 0.9186\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3183 - accuracy: 0.9451\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3310 - accuracy: 0.9184\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3238 - accuracy: 0.9483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubttlaZtbikY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d546afac-e284-4dc3-e25d-a8acad6d650e"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "print(len(train_acc))\n",
        "plt.plot(range(20),train_acc,color = 'red')\n",
        "plt.plot(range(20),train_loss,color = 'blue')\n",
        "plt.plot(range(20),test_acc,color = 'green')\n",
        "plt.plot(range(20),test_loss,color = 'pink')\n",
        "plt.gca().legend(('train_acc','train_loss','test_acc','test_loss'))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PGDlWC0wbhA",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "In this part of the workshop, we will be learning about convolutional layer, pooling layer and how it plays a part in image classification. \n",
        "\n",
        "Convolutional layer helps us identify relation between the pixel and its surrounding pixels. \n",
        "\n",
        "![alt text](https://miro.medium.com/max/654/1*hy15RJHCqT4HzO2VUydjTw.png)\n",
        "<br/>\n",
        "In the example given above, the convolutional layer creates a 3 X 3 filter which is labeled as K. This filter is used on the original image to find the relation between the pixels by applying the filter for every set of of pixel. In this example, the filter is multiplied to the original image pixel and then the values are added to give a new 2D array. Convolutions can be performed multiple times and can have different dimensions to improve the models prediction.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-lFsNHTzB1j",
        "colab_type": "text"
      },
      "source": [
        "Pooling layer reduce the spatial size of the representation to reduce the amount of parameters and computation in the network. While using the pool layer, we need to make sure that we reduce the size to help in computation without losing important features which will help in classification. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLO-eDLLy-Nb",
        "colab_type": "text"
      },
      "source": [
        "![alt text](data:image/jpeg;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXGgtNCx0EDx",
        "colab_type": "text"
      },
      "source": [
        "In the example given above, max pooling with 2 x 2 filter is used to find the largest number in 2x2 filter and create a smaller 2D array for computation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E0zLx07ynBp",
        "colab_type": "text"
      },
      "source": [
        "For computer vision, we are going to use couple of convolutional and pooling layers to compute the data and then flatten this data into a 1D array. After flattening it, we use dense layer to compute the data and find the image classification. \n",
        "\n",
        "![alt text](data:image/jpeg;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seGl8E5mNaC-",
        "colab_type": "text"
      },
      "source": [
        "### Creating convolutional and pooling layers\n",
        "\n",
        "In the code given below, we have created one convolutional layer and one max pooling layer.\n",
        "\n",
        "In the convolutional layer, we have created 64 filter of the size 3x3 which are used to compute the images (which are 2D lists). We have to specify the input shape for the first later which is 28 x 28 with our dataset. There is a third entry in the input shape which signifies the total number of bytes for the image. As our image is black and white, we use only one byte but for image whereas for coloured images, we use 3 bytes therefore the entry should be changed to 3 if we are using a dataset with colored images\n",
        "\n",
        "In the max pooling layer, we are just providing the size of the size of the filter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUeDOpBnsc_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu', input_shape = (28,28,1)),\n",
        "                            tf.keras.layers.MaxPooling2D(2,2),\n",
        "                            tf.keras.layers.Flatten(),\n",
        "                            tf.keras.layers.Dense(128, activation = 'relu'),\n",
        "                            tf.keras.layers.Dense(10, activation = 'softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXBMy6X6QL3h",
        "colab_type": "text"
      },
      "source": [
        "You may have observed that we have used a flatten layer in the middle of the model. This is because when the image is sent to our model, it is firsted computed through convolutional and max pooling layers which are 2D layers. After being computed in these layers, we flatten the data into a 1D list which is then computed through the dense layers and an output is generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBTJtMTPOgQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "2695e0f2-f5df-4b5b-c033-abe27ee60d42"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False)\n",
        "model.compile(optimizer = adam,\n",
        "              loss= 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10816)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               1384576   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,386,506\n",
            "Trainable params: 1,386,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0lnUdLMQDnb",
        "colab_type": "text"
      },
      "source": [
        "Model.summary() tells us about the output shape of each layers and how many parameters are trained in total. This helps us understand how the data is flowing through our neural network. \n",
        "\n",
        "In the first layer, we take an input size of 28 x 28 and generate an output of 26 x 26. This is because our convolutional layer has a filter size of 3 x 3. So it takes 3 x 3 pixels from left to write and computes them one by one. After computing 28 x 28 layer with a 3 x 3 filter, an output of size 26 x 26 is generated. As we have used 64 filters, we have generated 64 outputs of size 26 x 26. \n",
        "\n",
        "In ther second layer, we perform max pooling which takes 2 x 2 pixels form the image and finds the maximum value. This reduces the output image size to 13 x 13\n",
        "\n",
        "After the second layer, we pass this data through the flatten layer which then allows this data to go through the dense layer and provide us with an output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qydGctdycVf7",
        "colab_type": "text"
      },
      "source": [
        "### Exercise 2 : Sort the clothes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P44oVOMkciVi",
        "colab_type": "text"
      },
      "source": [
        "Create a convolutional neural network to classify images of the Fashion MNIST dataset.\n",
        "\n",
        "[Fashion-MNIST](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples.\n",
        "\n",
        "Each example is a 28x28 grayscale image, associated with a label from 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4KUrPQdI8OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout)\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Mqor1RcVJVH"
      },
      "source": [
        "**Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0dn3E2WeLpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load data from fashion_mnist into sets for training and testing\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#assign names to labels\n",
        "class_names={0:'top', 1:'trouser', 2:'pullover', 3:'dress', 4:'coat', 5:'sandal', 6:'shirt', 7:'sneaker', 8:'bag', 9:'boot'}\n",
        "\n",
        "#visualize data\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap='binary')\n",
        "    plt.xlabel(class_names[train_labels[i]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5uUiyqWdWWQ",
        "colab_type": "text"
      },
      "source": [
        "**Pre-process data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjzS9q3SI6vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize the images\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#reshape the images\n",
        "#YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUik3_qFdl5M",
        "colab_type": "text"
      },
      "source": [
        "**Build model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyJdgGvJI822",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = #YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTxkbNoadozr",
        "colab_type": "text"
      },
      "source": [
        "**Train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZX-ofwbI9Uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = adam, loss= 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(\"\"\"YOUR CODE HERE\"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15ZICl5qdsDw",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate perfomance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koCOUiQ0I91Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss, acc = #YOUR CODE HERE\n",
        "print(\"Training : loss={:.3f} - acc={:.3f}\".format(loss, acc))\n",
        "\n",
        "loss, acc = #YOUR CODE HERE\n",
        "print(\"Test : loss={:.3f} - acc={:.3f}\".format(loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRR1-nQaeAmj",
        "colab_type": "text"
      },
      "source": [
        "**Improve model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-MgNtL3jSpu",
        "colab_type": "text"
      },
      "source": [
        "If you observed over-fitting, improve your model by using regularization.\n",
        "\n",
        "NOTE ON DROPOUT REGULARIZATION\n",
        "\n",
        "Dropout randomly sets the output for a given neuron to 0. In setting the output to 0, the cost function becomes more sensitive to neighbouring neurons and this changes how weights will be updated during backpropagation.\n",
        "\n",
        "Dropout is implemented per-layer and may be implemented on any or all hidden layers in the network as well as the input layer. \n",
        "\n",
        "The hyperparameter specifies the probability at which outputs of the layer are dropped out/retained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2D71xlTI-fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_improved = #YOUR CODE HERE "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNE0VHJHecKx",
        "colab_type": "text"
      },
      "source": [
        "**Re-evaluate performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0C1eezF3LjzU",
        "colab": {}
      },
      "source": [
        "loss, acc = #YOUR CODE HERE\n",
        "print(\"Training : loss={:.3f} - acc={:.3f}\".format(loss, acc))\n",
        "\n",
        "loss, acc = #YOUR CODE HERE\n",
        "print(\"Test : loss={:.3f} - acc={:.3f}\".format(loss, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP4Df0a1mIEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get output probabilities and select class name\n",
        "predictions = #YOUR CODE HERE\n",
        "\n",
        "#visualize predictions \n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[i], cmap='binary')\n",
        "    actual_class=class_names[test_labels[i]]\n",
        "    if predictions[i]==test_labels[i]:\n",
        "      plt.xlabel(actual_class, color='green')\n",
        "    else:\n",
        "      plt.xlabel(actual_class, color='red')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OigKVi83pJRn"
      },
      "source": [
        "### Exercise 3 : Want to watch a movie this weekend?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4oINNwHp0XP",
        "colab_type": "text"
      },
      "source": [
        "Create a model to categorise movie reviews of the [IMDB dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
        "\n",
        "This is a dataset of highly-polarized movies reviews from IMDB labeled by binary sentiment (1 for positive and 0 for negative), consisting of 25000 training examples and 25000 testing examples.\n",
        "\n",
        "Reviews have been preprocessed, and each review is encoded as a list of word indices (integers). Words are indexed by overall frequency in the dataset, for instance the integer \"3\" encodes the 3rd most frequently occuring word. \n",
        "\n",
        "NOTE ON WORD INDICES\n",
        "\n",
        "The encoding is actually offset because of reserved indices 0, 1 and 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m1Nyiutx-vq",
        "colab_type": "text"
      },
      "source": [
        "**Load dataset**\n",
        "\n",
        "[Check the reference doc here](https://keras.io/api/datasets/imdb/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwXaRZpm5SDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import imdb\n",
        "#load data, using 10000 for num_words parameter\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#merge training examples and testing examples, so that we can change from 50/50 to 80/20 split distribution\n",
        "data = #YOUR CODE HERE\n",
        "targets = #YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75U07bu99OE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#try exploring the data at your own time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1hAmuG6x8hi",
        "colab_type": "text"
      },
      "source": [
        "**Pre-process data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EWlZ32Bzk_q",
        "colab_type": "text"
      },
      "source": [
        "The whole dataset contains 9,998 unique words.\n",
        "\n",
        "You can’t feed lists of integers into a neural network, so we will vectorize every review into a 10,000-dimensional vector. \n",
        "\n",
        "For instance, the sequence [3, 5] will be turned into a 10,000-dimensional vector with all zeros except at indices 3 and 5, which would be ones.\n",
        "\n",
        "Now we can use as the first layer in your network a dense layer, capable of handling floating-point vector data.\n",
        "\n",
        "Don't forget to split data into 80/20 for training/testing!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5npPa5SsMoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to visualize predictions later, keep a copy of non-vectorized test examples\n",
        "check_x = data[:10000]\n",
        "check_y = targets[:10000]\n",
        "\n",
        "def vectorize(sequences, dimension = 10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1\n",
        "  return results\n",
        "\n",
        "#vectorize reviews and labels\n",
        "data = #YOUR CODE HERE \n",
        "targets = np.array(targets).astype(\"float32\")\n",
        "\n",
        "#first 10K reviews for testing\n",
        "#YOUR CODE HERE\n",
        "\n",
        "#last 40K reviews for training\n",
        "#YOUR CODE HERE "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrz6DuJZv25a",
        "colab_type": "text"
      },
      "source": [
        "**Build model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG90TTTY_Kyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = #YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkPQmpzkv3K9",
        "colab_type": "text"
      },
      "source": [
        "**Train model and evaluate performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEuoNn0r_ODk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "results = model.fit('''YOUR CODE HERE''', validation_data = ('''YOUR CODE HERE'''))\n",
        "\n",
        "print(\"Test-Accuracy:\", np.mean(results.history[\"accuracy\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1Z0PM40_RxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the get_word_index function retrieves a dictionary mapping words to their index in the dataset\n",
        "index = imdb.get_word_index()     \n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
        "\n",
        "#to read the review\n",
        "#note that indices were offset by 3, because 0, 1 and 2 are reserved indices for \"padding\", \"start of sequence\", and \"unknown\"\n",
        "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in check_x[0]] )\n",
        "print(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o02XVVg__Ujj",
        "colab_type": "text"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfU17njv_jP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#binary classification\n",
        "sentiment = {1: 'positive', 0:'negative'}\n",
        "\n",
        "#get output probabilities \n",
        "predictions = #YOUR CODE HERE\n",
        "\n",
        "predictions = np.round(predictions).astype('int64')\n",
        "print(\"predicted: \", sentiment[predictions[0][0]])\n",
        "print(\"actual: \", sentiment[check_y[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bO-mDkJbG5xM",
        "colab_type": "text"
      },
      "source": [
        "# Jupyter Notebook option for Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWEqA3iYG40J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install tensorflow \n",
        "# locally installs tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8orKGEMIGcJB",
        "colab_type": "text"
      },
      "source": [
        "# Biblography\n",
        "\n",
        "\n",
        "*   TensorFlow Official Website - https://www.tensorflow.org/\n",
        "*   Introduction to Tensorflow for AI, ML and DL by Deeplearning.ai - https://www.coursera.org/learn/introduction-tensorflow\n",
        "*   What is Tensorflow? by Python Programmer - https://www.youtube.com/watch?v=UbMDK4UNtPA&t=38s\n",
        "* A Gentle Introduction to Dropout for Regularizing Deep Neural Networks by Jason Brownlee - https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/\n",
        "\n",
        "\n",
        "## Keras Documentation\n",
        "* Built-in datasets - https://keras.io/api/datasets/\n",
        "* Models - https://keras.io/api/models/model/ and https://keras.io/api/models/sequential/#sequential-class\n",
        "* Layers - https://keras.io/api/layers/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-krfN_6ScVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}